{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2abfad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6179bf31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb51c0c8b90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 47\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9567484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu') if not torch.cuda.is_available() else torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4c31186",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist = FashionMNIST(root=\"./data\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cef51a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-shirt/top Trouser Pullover Dress Coat Sandal Shirt Sneaker Bag Ankle boot\n"
     ]
    }
   ],
   "source": [
    "print(*fmnist.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21c6540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = (fmnist.targets == fmnist.class_to_idx[\"Sneaker\"]) | (fmnist.targets == fmnist.class_to_idx[\"Shirt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d82e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist.data = fmnist.data[ix]\n",
    "fmnist.targets = fmnist.targets[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c3aed16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12000, 28, 28]), tensor([7, 7, 6,  ..., 6, 6, 7]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmnist.data.shape, fmnist.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "632b8adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.ConvTranspose2d( 100, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d( 256, 128, 4, 2, 2, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d( 128, 1, 4, 2, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.network(X)\n",
    "    \n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(1, 128, 5),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128, 256, 3, 2, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 512, 3, 2, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512*5*5, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.network(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d457df08",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "fixed_noise = torch.randn(64, 100, 1, 1, device=device)\n",
    "\n",
    "gen = Generator()\n",
    "gen.to(device)\n",
    "dis = Discriminator()\n",
    "dis.to(device)\n",
    "\n",
    "\n",
    "optimizerD = torch.optim.Adam(dis.parameters())\n",
    "optimizerG = torch.optim.Adam(gen.parameters())\n",
    "\n",
    "writer = SummaryWriter(\"./runs/exp2\")\n",
    "\n",
    "dataloader = DataLoader(fmnist, batch_size=64, shuffle=True)\n",
    "n_epochs = 20\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0902326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/20]\n",
      "Step: [180/188]\tLoss_D: 0.0007\tLoss_G: 8.0011\n",
      "Epoch: [2/20]\n",
      "Step: [180/188]\tLoss_D: 0.0206\tLoss_G: 7.05365\n",
      "Epoch: [3/20]\n",
      "Step: [180/188]\tLoss_D: 0.5378\tLoss_G: 7.9691\n",
      "Epoch: [4/20]\n",
      "Step: [180/188]\tLoss_D: 0.7044\tLoss_G: 5.3533\n",
      "Epoch: [5/20]\n",
      "Step: [180/188]\tLoss_D: 1.2569\tLoss_G: 3.8079\n",
      "Epoch: [6/20]\n",
      "Step: [180/188]\tLoss_D: 0.6442\tLoss_G: 5.3688\n",
      "Epoch: [7/20]\n",
      "Step: [180/188]\tLoss_D: 2.2146\tLoss_G: 2.3744\n",
      "Epoch: [8/20]\n",
      "Step: [180/188]\tLoss_D: 0.3025\tLoss_G: 3.3341\n",
      "Epoch: [9/20]\n",
      "Step: [180/188]\tLoss_D: 0.6280\tLoss_G: 3.6359\n",
      "Epoch: [10/20]\n",
      "Step: [180/188]\tLoss_D: 1.1844\tLoss_G: 3.8985\n",
      "Epoch: [11/20]\n",
      "Step: [180/188]\tLoss_D: 1.7398\tLoss_G: 2.7523\n",
      "Epoch: [12/20]\n",
      "Step: [180/188]\tLoss_D: 0.7605\tLoss_G: 3.3881\n",
      "Epoch: [13/20]\n",
      "Step: [180/188]\tLoss_D: 1.7704\tLoss_G: 0.9365\n",
      "Epoch: [14/20]\n",
      "Step: [180/188]\tLoss_D: 0.7932\tLoss_G: 2.5801\n",
      "Epoch: [15/20]\n",
      "Step: [180/188]\tLoss_D: 0.5246\tLoss_G: 2.8098\n",
      "Epoch: [16/20]\n",
      "Step: [180/188]\tLoss_D: 1.1541\tLoss_G: 4.2631\n",
      "Epoch: [17/20]\n",
      "Step: [180/188]\tLoss_D: 0.4714\tLoss_G: 7.4326\n",
      "Epoch: [18/20]\n",
      "Step: [180/188]\tLoss_D: 0.6679\tLoss_G: 1.6319\n",
      "Epoch: [19/20]\n",
      "Step: [180/188]\tLoss_D: 0.4258\tLoss_G: 2.6660\n",
      "Epoch: [20/20]\n",
      "Step: [180/188]\tLoss_D: 0.6517\tLoss_G: 2.3209\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch: [{epoch+1}/{n_epochs}]\")\n",
    "    for i, (x, y) in enumerate(dataloader, 1):\n",
    "        \n",
    "        optimizerD.zero_grad()\n",
    "        \n",
    "        real_x = x.to(device)\n",
    "        \n",
    "        b_size = real_x.size(0)\n",
    "        label = torch.full((b_size,1), 1, dtype=torch.float, device=device)\n",
    "        \n",
    "        output = dis(real_x)\n",
    "        err_real_D = criterion(output, label)\n",
    "        err_real_D.backward()\n",
    "        \n",
    "        noise = torch.randn(b_size, 100, 1, 1, device=device)\n",
    "        fake_x = gen(noise)\n",
    "        label.fill_(0)\n",
    "        output = dis(fake_x.detach())\n",
    "        err_fake_D = criterion(output, label)\n",
    "        err_fake_D.backward()\n",
    "        \n",
    "        err_D = err_real_D + err_fake_D\n",
    "        optimizerD.step()\n",
    "        \n",
    "        optimizerG.zero_grad()\n",
    "        \n",
    "        label.fill_(1)\n",
    "        for j in range(k):\n",
    "            noise = torch.randn(b_size, 100, 1, 1, device=device)\n",
    "            fake_x = gen(noise)\n",
    "            output = dis(fake_x)\n",
    "            err_G = criterion(output, label)\n",
    "            err_G.backward()\n",
    "\n",
    "            optimizerG.step()\n",
    "        \n",
    "        if i%10 == 0:\n",
    "            print(\"\\rStep: [%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\"%(i, len(dataloader), err_D.item(), err_G.item()), end=\"\")\n",
    "            writer.add_scalar('Loss/Discriminator', err_D.item(), epoch*len(dataloader)+i)\n",
    "            writer.add_scalar('Loss/Generator', err_G.item(), epoch*len(dataloader)+i)\n",
    "            \n",
    "            if i%30 == 0:\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    fake_imgs = gen(fixed_noise).detach().cpu()\n",
    "                \n",
    "                grid = torchvision.utils.make_grid(fake_imgs)\n",
    "                writer.add_image('Generated Image', grid, epoch*len(dataloader)+i)\n",
    "                \n",
    "                if epoch == 0:\n",
    "                    grid = torchvision.utils.make_grid(real_x)\n",
    "                    writer.add_image('Real Image', grid, epoch*len(dataloader)+i)\n",
    "\n",
    "    print()\n",
    "    \n",
    "    torch.save(gen.state_dict(), \"./generator.pth\")\n",
    "    torch.save(dis.state_dict(), \"./discriminator.pth\")\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce13221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
